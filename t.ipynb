{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoZ3WW3IWiyF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "! pip install \"granite-tsfm[notebooks] @ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gfqKiyGQWiyI"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments, set_seed\n",
        "from transformers.integrations import INTEGRATION_TO_CALLBACK\n",
        "\n",
        "from tsfm_public import TimeSeriesPreprocessor, TrackingCallback, count_parameters, get_datasets\n",
        "from tsfm_public.toolkit.get_model import get_model\n",
        "from tsfm_public.toolkit.lr_finder import optimal_lr_finder\n",
        "from tsfm_public.toolkit.visualization import plot_predictions\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "import warnings\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYPPzcXSXviI",
        "outputId": "aa54a2f4-7b53-4357-b7a2-75578dfe22cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'testing_dataset.csv', 'training_dataset.csv', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8534TTFZWiyJ"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "\n",
        "# TTM Model path. The default model path is Granite-R2. Below, you can choose other TTM releases.\n",
        "TTM_MODEL_PATH = \"ibm-granite/granite-timeseries-ttm-r2\"\n",
        "# TTM_MODEL_PATH = \"ibm-granite/granite-timeseries-ttm-r1\"\n",
        "# TTM_MODEL_PATH = \"ibm-research/ttm-research-r2\"\n",
        "\n",
        "# Context length, Or Length of the history.\n",
        "# Currently supported values are: 512/1024/1536 for Granite-TTM-R2 and Research-Use-TTM-R2, and 512/1024 for Granite-TTM-R1\n",
        "CONTEXT_LENGTH = 512\n",
        "\n",
        "# Granite-TTM-R2 supports forecast length upto 720 and Granite-TTM-R1 supports forecast length upto 96\n",
        "PREDICTION_LENGTH = 96\n",
        "\n",
        "TARGET_DATASET = \"etth1\"\n",
        "dataset_path = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv\"\n",
        "\n",
        "\n",
        "# Results dir\n",
        "OUT_DIR = \"ttm_finetuned_models/\"\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "J_BQ_oEJWiyK"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "TARGET_DATASET = \"datavidia\"\n",
        "dataset_path = \"./training_dataset.csv\"\n",
        "test_dataset_path = \"./testing_dataset.csv\"\n",
        "timestamp_column = \"Date\"\n",
        "id_columns = ['commodity', 'province']\n",
        "target_columns = ['price']\n",
        "split_config = {\n",
        "    \"train\": 0.8,\n",
        "    \"test\": 0.1\n",
        "}\n",
        "\n",
        "test_split_config = {\n",
        "    \"train\": 0.8,\n",
        "    \"test\": 0.1\n",
        "}\n",
        "\n",
        "# Understanding the split config -- slides\n",
        "\n",
        "feature_to_scale = ['GlobalOpen', 'GlobalHigh', 'GlobalVol.', 'GlobalPrice', 'CE_Close', 'CE_High', 'CE_Low', 'CE_Open']\n",
        "\n",
        "data = pd.read_csv(\n",
        "    dataset_path,\n",
        "    parse_dates=[timestamp_column],\n",
        ")\n",
        "\n",
        "test_data = pd.read_csv(\n",
        "    test_dataset_path,\n",
        "    parse_dates=[timestamp_column],\n",
        ")\n",
        "\n",
        "column_specifiers = {\n",
        "    \"timestamp_column\": timestamp_column,\n",
        "    \"id_columns\": id_columns,\n",
        "    \"target_columns\": target_columns,\n",
        "    \"control_columns\": [],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(df: pd.DataFrame):\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df['timestamp'] = df['Date'].astype(int)\n",
        "    df['timestamp'] = df['timestamp'].div(10**9)\n",
        "\n",
        "    df['province'] = label_encoder.fit_transform(df['province'])\n",
        "    df['commodity'] = label_encoder.fit_transform(df['commodity'])\n",
        "\n",
        "    df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "    for col in feature_to_scale:\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "    return df"
      ],
      "metadata": {
        "id": "4wUyeKGhazUu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DUKaQPMkWiyL"
      },
      "outputs": [],
      "source": [
        "data = process_dataset(data)\n",
        "test_data = process_dataset(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "3C9B1WLwWiyL",
        "outputId": "56deffa1-a0f1-4ad0-b538-76090e02ca56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date  commodity  province    price  GlobalOpen  GlobalHigh  GlobalLow  \\\n",
              "0 2022-01-01          0         0  28970.0    0.384917    0.977176        3.5   \n",
              "1 2022-01-01          1         0  27440.0    0.384917    0.977176        3.5   \n",
              "2 2022-01-01          2         0  11030.0    0.384917    0.977176        3.5   \n",
              "3 2022-01-01          3         0  12080.0    0.384917    0.977176        3.5   \n",
              "4 2022-01-01          4         0  22360.0    0.384917    0.977176        3.5   \n",
              "\n",
              "   GlobalVol.  GlobalChange %  GlobalPrice  CE_Close   CE_High    CE_Low  \\\n",
              "0   -1.266524           -0.48     0.316524 -1.932679 -1.862012  1.437183   \n",
              "1   -1.266524           -0.48     0.316524 -1.932679 -1.862012  1.437183   \n",
              "2   -1.266524           -0.48     0.316524 -1.932679 -1.862012  1.437183   \n",
              "3   -1.266524           -0.48     0.316524 -1.932679 -1.862012  1.437183   \n",
              "4   -1.266524           -0.48     0.316524 -1.932679 -1.862012  1.437183   \n",
              "\n",
              "   CE_Open     timestamp  \n",
              "0 -1.87819  1.640995e+09  \n",
              "1 -1.87819  1.640995e+09  \n",
              "2 -1.87819  1.640995e+09  \n",
              "3 -1.87819  1.640995e+09  \n",
              "4 -1.87819  1.640995e+09  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e71d6ba-8b40-4b69-afa7-23628a3dc310\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>commodity</th>\n",
              "      <th>province</th>\n",
              "      <th>price</th>\n",
              "      <th>GlobalOpen</th>\n",
              "      <th>GlobalHigh</th>\n",
              "      <th>GlobalLow</th>\n",
              "      <th>GlobalVol.</th>\n",
              "      <th>GlobalChange %</th>\n",
              "      <th>GlobalPrice</th>\n",
              "      <th>CE_Close</th>\n",
              "      <th>CE_High</th>\n",
              "      <th>CE_Low</th>\n",
              "      <th>CE_Open</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28970.0</td>\n",
              "      <td>0.384917</td>\n",
              "      <td>0.977176</td>\n",
              "      <td>3.5</td>\n",
              "      <td>-1.266524</td>\n",
              "      <td>-0.48</td>\n",
              "      <td>0.316524</td>\n",
              "      <td>-1.932679</td>\n",
              "      <td>-1.862012</td>\n",
              "      <td>1.437183</td>\n",
              "      <td>-1.87819</td>\n",
              "      <td>1.640995e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27440.0</td>\n",
              "      <td>0.384917</td>\n",
              "      <td>0.977176</td>\n",
              "      <td>3.5</td>\n",
              "      <td>-1.266524</td>\n",
              "      <td>-0.48</td>\n",
              "      <td>0.316524</td>\n",
              "      <td>-1.932679</td>\n",
              "      <td>-1.862012</td>\n",
              "      <td>1.437183</td>\n",
              "      <td>-1.87819</td>\n",
              "      <td>1.640995e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>11030.0</td>\n",
              "      <td>0.384917</td>\n",
              "      <td>0.977176</td>\n",
              "      <td>3.5</td>\n",
              "      <td>-1.266524</td>\n",
              "      <td>-0.48</td>\n",
              "      <td>0.316524</td>\n",
              "      <td>-1.932679</td>\n",
              "      <td>-1.862012</td>\n",
              "      <td>1.437183</td>\n",
              "      <td>-1.87819</td>\n",
              "      <td>1.640995e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-01-01</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>12080.0</td>\n",
              "      <td>0.384917</td>\n",
              "      <td>0.977176</td>\n",
              "      <td>3.5</td>\n",
              "      <td>-1.266524</td>\n",
              "      <td>-0.48</td>\n",
              "      <td>0.316524</td>\n",
              "      <td>-1.932679</td>\n",
              "      <td>-1.862012</td>\n",
              "      <td>1.437183</td>\n",
              "      <td>-1.87819</td>\n",
              "      <td>1.640995e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-01-01</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>22360.0</td>\n",
              "      <td>0.384917</td>\n",
              "      <td>0.977176</td>\n",
              "      <td>3.5</td>\n",
              "      <td>-1.266524</td>\n",
              "      <td>-0.48</td>\n",
              "      <td>0.316524</td>\n",
              "      <td>-1.932679</td>\n",
              "      <td>-1.862012</td>\n",
              "      <td>1.437183</td>\n",
              "      <td>-1.87819</td>\n",
              "      <td>1.640995e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e71d6ba-8b40-4b69-afa7-23628a3dc310')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e71d6ba-8b40-4b69-afa7-23628a3dc310 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e71d6ba-8b40-4b69-afa7-23628a3dc310');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d87bcd13-4bca-4336-892c-2961e4728b06\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d87bcd13-4bca-4336-892c-2961e4728b06')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d87bcd13-4bca-4336-892c-2961e4728b06 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['price'] = 0\n",
        "len(test_data)"
      ],
      "metadata": {
        "id": "UaICSLVA5iU-",
        "outputId": "e49cc595-afaa-4215-a61d-96b7f1782975",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40664"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_result(\n",
        "        model,\n",
        "        context_length: int = 512,\n",
        "        forecast_length: int = 96,\n",
        "        ) -> None:\n",
        "\n",
        "    tsp = TimeSeriesPreprocessor(\n",
        "        **column_specifiers,\n",
        "        context_length=context_length,\n",
        "        prediction_length=forecast_length,\n",
        "        scaling=True,\n",
        "        encode_categorical=False,\n",
        "        scaler_type=\"standard\",\n",
        "    )\n",
        "\n",
        "    dset, dset_val, dset_test = get_datasets(\n",
        "        tsp, test_data, test_split_config, fewshot_fraction=100 / 100, fewshot_location=\"first\"\n",
        "    )\n",
        "\n",
        "    print(f'dset: {len(dset)}')\n",
        "    print(f'val: {len(dset_val)}')\n",
        "    print(f'test: {len(dset_test)}')\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "mUUU1BKx2Vhi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_model_result(\"\")"
      ],
      "metadata": {
        "id": "XVjsVkTO3Q0H",
        "outputId": "191220e7-bab0-4310-a771-41d75616a4b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dset: 442\n",
            "val: 442\n",
            "test: 442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "XOKY1TpIWiyN"
      },
      "outputs": [],
      "source": [
        "def fewshot_finetune_eval(\n",
        "    dataset_name,\n",
        "    batch_size,\n",
        "    learning_rate=None,\n",
        "    context_length=512,\n",
        "    forecast_length=96,\n",
        "    fewshot_percent=5,\n",
        "    freeze_backbone=True,\n",
        "    num_epochs=50,\n",
        "    save_dir=OUT_DIR,\n",
        "    loss=\"mse\",\n",
        "    quantile=0.5,\n",
        "):\n",
        "    out_dir = os.path.join(save_dir, dataset_name)\n",
        "\n",
        "    print(\"-\" * 20, f\"Running few-shot {fewshot_percent}%\", \"-\" * 20)\n",
        "\n",
        "    # Data prep: Get dataset\n",
        "\n",
        "    tsp = TimeSeriesPreprocessor(\n",
        "        **column_specifiers,\n",
        "        context_length=context_length,\n",
        "        prediction_length=forecast_length,\n",
        "        scaling=True,\n",
        "        encode_categorical=False,\n",
        "        scaler_type=\"standard\",\n",
        "    )\n",
        "\n",
        "    dset_train, dset_val, dset_test = get_datasets(\n",
        "        tsp, data, split_config, fewshot_fraction=fewshot_percent / 100, fewshot_location=\"first\"\n",
        "    )\n",
        "\n",
        "    # change head dropout to 0.7 for ett datasets\n",
        "    if \"ett\" in dataset_name:\n",
        "        finetune_forecast_model = get_model(\n",
        "            TTM_MODEL_PATH,\n",
        "            context_length=context_length,\n",
        "            prediction_length=forecast_length,\n",
        "            freq_prefix_tuning=False,\n",
        "            freq=None,\n",
        "            prefer_l1_loss=False,\n",
        "            prefer_longer_context=True,\n",
        "            # Can also provide TTM Config args\n",
        "            head_dropout=0.7,\n",
        "            loss=loss,\n",
        "            quantile=quantile,\n",
        "        )\n",
        "    else:\n",
        "        finetune_forecast_model = get_model(\n",
        "            TTM_MODEL_PATH,\n",
        "            context_length=context_length,\n",
        "            prediction_length=forecast_length,\n",
        "            freq_prefix_tuning=False,\n",
        "            freq=None,\n",
        "            prefer_l1_loss=False,\n",
        "            prefer_longer_context=True,\n",
        "            # Can also provide TTM Config args\n",
        "            head_dropout=1,\n",
        "            loss=loss,\n",
        "            quantile=quantile,\n",
        "        )\n",
        "\n",
        "    if freeze_backbone:\n",
        "        print(\n",
        "            \"Number of params before freezing backbone\",\n",
        "            count_parameters(finetune_forecast_model),\n",
        "        )\n",
        "\n",
        "        # Freeze the backbone of the model\n",
        "        for param in finetune_forecast_model.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Count params\n",
        "        print(\n",
        "            \"Number of params after freezing the backbone\",\n",
        "            count_parameters(finetune_forecast_model),\n",
        "        )\n",
        "\n",
        "    # Find optimal learning rate\n",
        "    # Use with caution: Set it manually if the suggested learning rate is not suitable\n",
        "    if learning_rate is None:\n",
        "        learning_rate, finetune_forecast_model = optimal_lr_finder(\n",
        "            finetune_forecast_model,\n",
        "            dset_train,\n",
        "            batch_size=batch_size,\n",
        "        )\n",
        "        print(\"OPTIMAL SUGGESTED LEARNING RATE =\", learning_rate)\n",
        "\n",
        "    print(f\"Using learning rate = {learning_rate}\")\n",
        "    finetune_forecast_args = TrainingArguments(\n",
        "        output_dir=os.path.join(out_dir, \"output\"),\n",
        "        overwrite_output_dir=True,\n",
        "        learning_rate=learning_rate,\n",
        "        num_train_epochs=num_epochs,\n",
        "        do_eval=True,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        dataloader_num_workers=8,\n",
        "        report_to=\"none\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        save_total_limit=1,\n",
        "        logging_dir=os.path.join(out_dir, \"logs\"),  # Make sure to specify a logging directory\n",
        "        load_best_model_at_end=True,  # Load the best model when training ends\n",
        "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
        "        greater_is_better=False,  # For loss\n",
        "        seed=SEED,\n",
        "    )\n",
        "\n",
        "    # Create the early stopping callback\n",
        "    early_stopping_callback = EarlyStoppingCallback(\n",
        "        early_stopping_patience=10,  # Number of epochs with no improvement after which to stop\n",
        "        early_stopping_threshold=1e-5,  # Minimum improvement required to consider as improvement\n",
        "    )\n",
        "    tracking_callback = TrackingCallback()\n",
        "\n",
        "    # Optimizer and scheduler\n",
        "    optimizer = AdamW(finetune_forecast_model.parameters(), lr=learning_rate)\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        learning_rate,\n",
        "        epochs=num_epochs,\n",
        "        steps_per_epoch=math.ceil(len(dset_train) / (batch_size)),\n",
        "    )\n",
        "\n",
        "    finetune_forecast_trainer = Trainer(\n",
        "        model=finetune_forecast_model,\n",
        "        args=finetune_forecast_args,\n",
        "        train_dataset=dset_train,\n",
        "        eval_dataset=dset_val,\n",
        "        callbacks=[early_stopping_callback, tracking_callback],\n",
        "        optimizers=(optimizer, scheduler),\n",
        "    )\n",
        "    finetune_forecast_trainer.remove_callback(INTEGRATION_TO_CALLBACK[\"codecarbon\"])\n",
        "\n",
        "    # Fine tune\n",
        "    finetune_forecast_trainer.train()\n",
        "\n",
        "    # Evaluation\n",
        "    print(\"+\" * 20, f\"Test MSE after few-shot {fewshot_percent}% fine-tuning\", \"+\" * 20)\n",
        "\n",
        "    finetune_forecast_trainer.model.loss = \"mse\"  # fixing metric to mse for evaluation\n",
        "\n",
        "    fewshot_output = finetune_forecast_trainer.evaluate(dset_test)\n",
        "    print(fewshot_output)\n",
        "    print(\"+\" * 60)\n",
        "\n",
        "    # get predictions\n",
        "\n",
        "    predictions_dict = finetune_forecast_trainer.predict(dset_test)\n",
        "\n",
        "    predictions_np = predictions_dict.predictions[0]\n",
        "\n",
        "    print(predictions_np.shape)\n",
        "\n",
        "    # get backbone embeddings (if needed for further analysis)\n",
        "\n",
        "    backbone_embedding = predictions_dict.predictions[1]\n",
        "\n",
        "    print(backbone_embedding.shape)\n",
        "\n",
        "    # plot\n",
        "    # plot_predictions(\n",
        "    #     model=finetune_forecast_trainer.model,\n",
        "    #     dset=dset_test,\n",
        "    #     plot_dir=os.path.join(OUT_DIR, dataset_name),\n",
        "    #     plot_prefix=\"test_fewshot\",\n",
        "    #     channel=0,\n",
        "    # )\n",
        "    # view\n",
        "    view_prediction(dset_test, predictions_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EIcICKN3WiyN",
        "outputId": "217ec0eb-692f-4956-eeb8-653f48a83a3f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------- Running few-shot 5% --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:/usr/local/lib/python3.11/dist-packages/tsfm_public/toolkit/get_model.py:Loading model from: ibm-granite/granite-timeseries-ttm-r2\n",
            "INFO:/usr/local/lib/python3.11/dist-packages/tsfm_public/toolkit/get_model.py:Model loaded successfully from ibm-granite/granite-timeseries-ttm-r2, revision = main.\n",
            "INFO:/usr/local/lib/python3.11/dist-packages/tsfm_public/toolkit/get_model.py:[TTM] context_length = 512, prediction_length = 96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of params before freezing backbone 805280\n",
            "Number of params after freezing the backbone 289696\n",
            "Using learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14/14 00:02, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.004100</td>\n",
              "      <td>0.719330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TrackingCallback] Mean Epoch Time = 1.5764830112457275 seconds, Total Train Time = 3.6706032752990723\n",
            "++++++++++++++++++++ Test MSE after few-shot 5% fine-tuning ++++++++++++++++++++\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6005375981330872, 'eval_runtime': 1.2282, 'eval_samples_per_second': 470.611, 'eval_steps_per_second': 15.47, 'epoch': 1.0}\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "(578, 96, 1)\n",
            "(578, 1, 8, 192)\n",
            "{'past_values': tensor([[ 0.0000e+00],\n",
            "        [ 4.9788e-01],\n",
            "        [ 4.8613e-01],\n",
            "        [ 5.3316e-01],\n",
            "        [ 6.3115e-01],\n",
            "        [ 6.0763e-01],\n",
            "        [ 5.6060e-01],\n",
            "        [ 6.5467e-01],\n",
            "        [ 7.6246e-01],\n",
            "        [ 8.5261e-01],\n",
            "        [ 8.8201e-01],\n",
            "        [ 9.7020e-01],\n",
            "        [ 9.0945e-01],\n",
            "        [ 8.8985e-01],\n",
            "        [ 9.4864e-01],\n",
            "        [ 8.8397e-01],\n",
            "        [ 8.1538e-01],\n",
            "        [ 9.1337e-01],\n",
            "        [ 8.1929e-01],\n",
            "        [ 6.3507e-01],\n",
            "        [ 7.3894e-01],\n",
            "        [ 5.1944e-01],\n",
            "        [ 5.8804e-01],\n",
            "        [ 6.0567e-01],\n",
            "        [ 5.0180e-01],\n",
            "        [ 3.8421e-01],\n",
            "        [ 3.5286e-01],\n",
            "        [ 3.9793e-01],\n",
            "        [ 3.6462e-01],\n",
            "        [ 4.0577e-01],\n",
            "        [ 2.9210e-01],\n",
            "        [ 3.1954e-01],\n",
            "        [ 3.3522e-01],\n",
            "        [ 3.3130e-01],\n",
            "        [ 3.3914e-01],\n",
            "        [ 3.3130e-01],\n",
            "        [ 3.5874e-01],\n",
            "        [ 3.6854e-01],\n",
            "        [ 2.2743e-01],\n",
            "        [ 3.1954e-01],\n",
            "        [ 4.0185e-01],\n",
            "        [ 2.5487e-01],\n",
            "        [ 2.3331e-01],\n",
            "        [ 2.0979e-01],\n",
            "        [ 1.9803e-01],\n",
            "        [ 2.8622e-01],\n",
            "        [ 1.2552e-01],\n",
            "        [ 2.4507e-01],\n",
            "        [ 1.8039e-01],\n",
            "        [ 1.8235e-01],\n",
            "        [ 2.4115e-01],\n",
            "        [ 3.3522e-01],\n",
            "        [ 3.4110e-01],\n",
            "        [ 3.3522e-01],\n",
            "        [ 3.4502e-01],\n",
            "        [ 4.0185e-01],\n",
            "        [ 3.9989e-01],\n",
            "        [ 3.0778e-01],\n",
            "        [ 2.6467e-01],\n",
            "        [ 1.6863e-01],\n",
            "        [ 8.4362e-02],\n",
            "        [ 2.0587e-01],\n",
            "        [ 4.7125e-02],\n",
            "        [ 4.3206e-02],\n",
            "        [-3.3227e-02],\n",
            "        [ 5.4965e-02],\n",
            "        [-2.9308e-02],\n",
            "        [-2.2137e-01],\n",
            "        [-2.1353e-01],\n",
            "        [-3.0956e-01],\n",
            "        [-2.4293e-01],\n",
            "        [-3.0564e-01],\n",
            "        [-3.7620e-01],\n",
            "        [-3.7032e-01],\n",
            "        [-4.5851e-01],\n",
            "        [-3.7228e-01],\n",
            "        [-3.8012e-01],\n",
            "        [-3.7228e-01],\n",
            "        [-3.7620e-01],\n",
            "        [-3.7620e-01],\n",
            "        [-3.4288e-01],\n",
            "        [-5.9962e-01],\n",
            "        [-5.3690e-01],\n",
            "        [-4.5851e-01],\n",
            "        [-3.5072e-01],\n",
            "        [-2.5665e-01],\n",
            "        [-2.9584e-01],\n",
            "        [-6.5449e-01],\n",
            "        [-4.9183e-01],\n",
            "        [-4.8399e-01],\n",
            "        [-3.7620e-01],\n",
            "        [-4.3499e-01],\n",
            "        [-3.4876e-01],\n",
            "        [-4.6243e-01],\n",
            "        [-4.4283e-01],\n",
            "        [-5.3298e-01],\n",
            "        [-3.3504e-01],\n",
            "        [-2.8408e-01],\n",
            "        [-3.4092e-01],\n",
            "        [-3.3896e-01],\n",
            "        [-3.1544e-01],\n",
            "        [-3.0368e-01],\n",
            "        [-1.9393e-01],\n",
            "        [-1.3122e-01],\n",
            "        [ 3.5366e-02],\n",
            "        [-8.8102e-02],\n",
            "        [-7.8303e-02],\n",
            "        [-7.0464e-02],\n",
            "        [-2.0961e-01],\n",
            "        [-3.3504e-01],\n",
            "        [-1.8217e-01],\n",
            "        [-1.5866e-01],\n",
            "        [-1.0574e-01],\n",
            "        [-2.2725e-01],\n",
            "        [-5.4785e-02],\n",
            "        [-2.6253e-01],\n",
            "        [-2.5469e-01],\n",
            "        [-1.2926e-01],\n",
            "        [-2.4489e-01],\n",
            "        [-2.0177e-01],\n",
            "        [-1.7629e-01],\n",
            "        [-1.0182e-01],\n",
            "        [-2.7037e-01],\n",
            "        [-3.0760e-01],\n",
            "        [-2.6645e-01],\n",
            "        [-2.8408e-01],\n",
            "        [-3.1740e-01],\n",
            "        [-2.9976e-01],\n",
            "        [-2.2529e-01],\n",
            "        [-2.9976e-01],\n",
            "        [-4.4479e-01],\n",
            "        [-3.8208e-01],\n",
            "        [-2.8212e-01],\n",
            "        [-2.3313e-01],\n",
            "        [-3.7032e-01],\n",
            "        [-2.6449e-01],\n",
            "        [-2.7429e-01],\n",
            "        [-1.0574e-01],\n",
            "        [-1.1750e-01],\n",
            "        [-3.8301e-03],\n",
            "        [ 1.1572e-01],\n",
            "        [ 1.0592e-01],\n",
            "        [ 2.7838e-01],\n",
            "        [ 2.4507e-01],\n",
            "        [ 3.0386e-01],\n",
            "        [ 4.1753e-01],\n",
            "        [ 5.9784e-01],\n",
            "        [ 6.7819e-01],\n",
            "        [ 7.3698e-01],\n",
            "        [ 6.1743e-01],\n",
            "        [ 5.5864e-01],\n",
            "        [ 8.3693e-01],\n",
            "        [ 8.7613e-01],\n",
            "        [ 9.1141e-01],\n",
            "        [ 4.7633e-01],\n",
            "        [ 6.5271e-01],\n",
            "        [ 8.3693e-01],\n",
            "        [ 9.5256e-01],\n",
            "        [ 8.7809e-01],\n",
            "        [ 7.7618e-01],\n",
            "        [ 8.7221e-01],\n",
            "        [ 8.1929e-01],\n",
            "        [ 9.0553e-01],\n",
            "        [ 7.1150e-01],\n",
            "        [ 5.9588e-01],\n",
            "        [ 7.0758e-01],\n",
            "        [ 6.4095e-01],\n",
            "        [ 6.3507e-01],\n",
            "        [ 5.6060e-01],\n",
            "        [ 5.6452e-01],\n",
            "        [ 7.3502e-01],\n",
            "        [ 5.5864e-01],\n",
            "        [ 3.9205e-01],\n",
            "        [ 4.0773e-01],\n",
            "        [ 4.7633e-01],\n",
            "        [ 4.5281e-01],\n",
            "        [ 3.6462e-01],\n",
            "        [ 2.2743e-01],\n",
            "        [ 1.4316e-01],\n",
            "        [ 1.5492e-01],\n",
            "        [ 1.3808e-02],\n",
            "        [-8.0263e-02],\n",
            "        [-3.4484e-01],\n",
            "        [-3.8012e-01],\n",
            "        [-4.4087e-01],\n",
            "        [-4.8007e-01],\n",
            "        [-4.2911e-01],\n",
            "        [-6.2313e-01],\n",
            "        [-6.4861e-01],\n",
            "        [-6.7213e-01],\n",
            "        [-6.3293e-01],\n",
            "        [-6.4469e-01],\n",
            "        [-6.7409e-01],\n",
            "        [-6.3097e-01],\n",
            "        [-7.1720e-01],\n",
            "        [-8.2108e-01],\n",
            "        [-6.6821e-01],\n",
            "        [-8.5047e-01],\n",
            "        [-7.9560e-01],\n",
            "        [-8.2891e-01],\n",
            "        [-8.8771e-01],\n",
            "        [-8.4655e-01],\n",
            "        [-8.0344e-01],\n",
            "        [-9.3083e-01],\n",
            "        [-1.0778e+00],\n",
            "        [-1.0680e+00],\n",
            "        [-9.7590e-01],\n",
            "        [-9.2299e-01],\n",
            "        [-9.2691e-01],\n",
            "        [-1.0994e+00],\n",
            "        [-1.1484e+00],\n",
            "        [-1.1934e+00],\n",
            "        [-1.2522e+00],\n",
            "        [-1.2326e+00],\n",
            "        [-1.0308e+00],\n",
            "        [-1.1346e+00],\n",
            "        [-1.3345e+00],\n",
            "        [-1.5482e+00],\n",
            "        [-1.5188e+00],\n",
            "        [-1.6030e+00],\n",
            "        [-1.5874e+00],\n",
            "        [-1.7010e+00],\n",
            "        [-1.6952e+00],\n",
            "        [-1.7540e+00],\n",
            "        [-1.9401e+00],\n",
            "        [-1.8774e+00],\n",
            "        [-1.9049e+00],\n",
            "        [-1.9166e+00],\n",
            "        [-1.9127e+00],\n",
            "        [-1.9519e+00],\n",
            "        [-1.9009e+00],\n",
            "        [-1.9558e+00],\n",
            "        [-1.9950e+00],\n",
            "        [-2.0950e+00],\n",
            "        [-2.1185e+00],\n",
            "        [-2.0636e+00],\n",
            "        [-2.0832e+00],\n",
            "        [-1.9930e+00],\n",
            "        [-1.9715e+00],\n",
            "        [-1.9323e+00],\n",
            "        [-1.9401e+00],\n",
            "        [-1.9088e+00],\n",
            "        [-1.9539e+00],\n",
            "        [-1.8363e+00],\n",
            "        [-1.8657e+00],\n",
            "        [-1.9225e+00],\n",
            "        [-2.0107e+00],\n",
            "        [-1.9970e+00],\n",
            "        [-2.0303e+00],\n",
            "        [-2.0656e+00],\n",
            "        [-2.2478e+00],\n",
            "        [-2.1773e+00],\n",
            "        [-2.1126e+00],\n",
            "        [-2.1890e+00],\n",
            "        [-2.1165e+00],\n",
            "        [-2.0264e+00],\n",
            "        [-1.8598e+00],\n",
            "        [-1.8010e+00],\n",
            "        [-1.9519e+00],\n",
            "        [-1.8539e+00],\n",
            "        [-1.8696e+00],\n",
            "        [-2.0322e+00],\n",
            "        [-2.0224e+00],\n",
            "        [-1.9401e+00],\n",
            "        [-2.0166e+00],\n",
            "        [-2.0048e+00],\n",
            "        [-1.9872e+00],\n",
            "        [-2.0499e+00],\n",
            "        [-2.1028e+00],\n",
            "        [-2.0362e+00],\n",
            "        [-2.0048e+00],\n",
            "        [-2.1028e+00],\n",
            "        [-2.0616e+00],\n",
            "        [-1.9519e+00],\n",
            "        [-2.0166e+00],\n",
            "        [-1.7971e+00],\n",
            "        [-1.9597e+00],\n",
            "        [-1.7363e+00],\n",
            "        [-1.9617e+00],\n",
            "        [-1.8029e+00],\n",
            "        [-1.8127e+00],\n",
            "        [-1.7618e+00],\n",
            "        [-1.8108e+00],\n",
            "        [-1.8363e+00],\n",
            "        [-1.7167e+00],\n",
            "        [-1.6266e+00],\n",
            "        [-1.6011e+00],\n",
            "        [-1.5736e+00],\n",
            "        [-1.4874e+00],\n",
            "        [-1.4012e+00],\n",
            "        [-1.1915e+00],\n",
            "        [-1.0033e+00],\n",
            "        [-9.2103e-01],\n",
            "        [-9.5826e-01],\n",
            "        [-9.0339e-01],\n",
            "        [-6.6625e-01],\n",
            "        [-7.5444e-01],\n",
            "        [-8.5831e-01],\n",
            "        [-7.4072e-01],\n",
            "        [-7.3876e-01],\n",
            "        [-7.1329e-01],\n",
            "        [-7.4464e-01],\n",
            "        [-7.3288e-01],\n",
            "        [-7.6424e-01],\n",
            "        [-8.6811e-01],\n",
            "        [-7.2112e-01],\n",
            "        [-6.2509e-01],\n",
            "        [-5.4082e-01],\n",
            "        [-4.4087e-01],\n",
            "        [-4.8203e-01],\n",
            "        [-3.3112e-01],\n",
            "        [-4.3695e-01],\n",
            "        [-4.2911e-01],\n",
            "        [-3.9187e-01],\n",
            "        [-5.3690e-01],\n",
            "        [-4.4675e-01],\n",
            "        [-4.6243e-01],\n",
            "        [-5.2906e-01],\n",
            "        [-3.7620e-01],\n",
            "        [-3.6836e-01],\n",
            "        [-2.6645e-01],\n",
            "        [-2.8800e-01],\n",
            "        [-2.5861e-01],\n",
            "        [-2.1549e-01],\n",
            "        [-9.2022e-02],\n",
            "        [ 2.3607e-02],\n",
            "        [ 2.8034e-01],\n",
            "        [-5.7899e-03],\n",
            "        [ 1.6275e-01],\n",
            "        [ 2.0494e-03],\n",
            "        [ 6.6723e-02],\n",
            "        [ 1.7647e-01],\n",
            "        [ 2.4703e-01],\n",
            "        [ 1.9607e-01],\n",
            "        [ 2.9406e-01],\n",
            "        [ 4.6849e-01],\n",
            "        [ 7.5658e-01],\n",
            "        [ 4.2537e-01],\n",
            "        [ 6.7819e-01],\n",
            "        [ 7.2326e-01],\n",
            "        [ 7.7814e-01],\n",
            "        [ 6.8995e-01],\n",
            "        [ 8.0754e-01],\n",
            "        [ 9.9372e-01],\n",
            "        [ 9.5060e-01],\n",
            "        [ 9.5452e-01],\n",
            "        [ 9.6236e-01],\n",
            "        [ 1.1525e+00],\n",
            "        [ 9.9372e-01],\n",
            "        [ 1.2701e+00],\n",
            "        [ 1.2603e+00],\n",
            "        [ 1.2583e+00],\n",
            "        [ 1.3837e+00],\n",
            "        [ 1.2818e+00],\n",
            "        [ 1.2661e+00],\n",
            "        [ 1.3249e+00],\n",
            "        [ 1.2367e+00],\n",
            "        [ 1.2857e+00],\n",
            "        [ 1.1289e+00],\n",
            "        [ 1.0251e+00],\n",
            "        [ 9.0161e-01],\n",
            "        [ 8.3301e-01],\n",
            "        [ 5.2140e-01],\n",
            "        [ 3.2934e-01],\n",
            "        [ 5.4492e-01],\n",
            "        [ 4.3713e-01],\n",
            "        [ 3.9793e-01],\n",
            "        [ 5.6060e-01],\n",
            "        [ 3.1954e-01],\n",
            "        [ 2.1567e-01],\n",
            "        [ 2.0391e-01],\n",
            "        [ 8.4362e-02],\n",
            "        [ 2.1959e-01],\n",
            "        [ 3.1447e-02],\n",
            "        [-4.1067e-02],\n",
            "        [ 2.5567e-02],\n",
            "        [ 1.1768e-01],\n",
            "        [ 1.6667e-01],\n",
            "        [ 1.5688e-01],\n",
            "        [ 1.4904e-01],\n",
            "        [ 7.2603e-02],\n",
            "        [ 1.6863e-01],\n",
            "        [ 1.5492e-01],\n",
            "        [ 2.3607e-02],\n",
            "        [ 1.0788e-01],\n",
            "        [ 1.2944e-01],\n",
            "        [ 1.8039e-01],\n",
            "        [ 3.0190e-01],\n",
            "        [ 2.3919e-01],\n",
            "        [ 2.0783e-01],\n",
            "        [ 4.1165e-01],\n",
            "        [ 5.0572e-01],\n",
            "        [ 4.9004e-01],\n",
            "        [ 5.0572e-01],\n",
            "        [ 6.8603e-01],\n",
            "        [ 5.3708e-01],\n",
            "        [ 6.0567e-01],\n",
            "        [ 6.8603e-01],\n",
            "        [ 5.9979e-01],\n",
            "        [ 5.7236e-01],\n",
            "        [ 6.6839e-01],\n",
            "        [ 6.5467e-01],\n",
            "        [ 6.0175e-01],\n",
            "        [ 7.2326e-01],\n",
            "        [ 6.9779e-01],\n",
            "        [ 6.5271e-01],\n",
            "        [ 7.5070e-01],\n",
            "        [ 7.5266e-01],\n",
            "        [ 1.0310e+00],\n",
            "        [ 9.0161e-01],\n",
            "        [ 9.2121e-01],\n",
            "        [ 8.3497e-01],\n",
            "        [ 8.4281e-01],\n",
            "        [ 8.4477e-01],\n",
            "        [ 6.8603e-01],\n",
            "        [ 8.0166e-01],\n",
            "        [ 5.9196e-01],\n",
            "        [ 6.4487e-01],\n",
            "        [ 6.8799e-01],\n",
            "        [ 6.5467e-01],\n",
            "        [ 7.4874e-01],\n",
            "        [ 7.5266e-01],\n",
            "        [ 7.2522e-01],\n",
            "        [ 8.1538e-01],\n",
            "        [ 8.0558e-01],\n",
            "        [ 7.9774e-01],\n",
            "        [ 8.2517e-01],\n",
            "        [ 8.1146e-01],\n",
            "        [ 8.0558e-01],\n",
            "        [ 1.2387e+00],\n",
            "        [ 1.3073e+00],\n",
            "        [ 1.2916e+00],\n",
            "        [ 1.5248e+00],\n",
            "        [ 1.9560e+00],\n",
            "        [ 2.1402e+00],\n",
            "        [ 2.5145e+00],\n",
            "        [ 2.9398e+00],\n",
            "        [ 2.7242e+00],\n",
            "        [ 2.7615e+00],\n",
            "        [ 2.6576e+00],\n",
            "        [ 2.7321e+00],\n",
            "        [ 2.6890e+00],\n",
            "        [ 3.5317e+00],\n",
            "        [ 3.8257e+00],\n",
            "        [ 4.2549e+00],\n",
            "        [ 4.7272e+00],\n",
            "        [ 4.8898e+00],\n",
            "        [ 5.2328e+00],\n",
            "        [ 5.1544e+00],\n",
            "        [ 5.4288e+00],\n",
            "        [ 5.3524e+00],\n",
            "        [ 5.2975e+00],\n",
            "        [ 5.3543e+00],\n",
            "        [ 5.3347e+00],\n",
            "        [ 5.2661e+00],\n",
            "        [ 5.1603e+00],\n",
            "        [ 4.9369e+00],\n",
            "        [ 4.9388e+00],\n",
            "        [ 4.9192e+00],\n",
            "        [ 4.7781e+00],\n",
            "        [ 4.8957e+00],\n",
            "        [ 4.8193e+00],\n",
            "        [ 4.7409e+00],\n",
            "        [ 4.7997e+00],\n",
            "        [ 4.7272e+00],\n",
            "        [ 4.7487e+00],\n",
            "        [ 4.8017e+00],\n",
            "        [ 4.8350e+00],\n",
            "        [ 4.6684e+00],\n",
            "        [ 4.5626e+00],\n",
            "        [ 4.3920e+00],\n",
            "        [ 4.1823e+00],\n",
            "        [ 4.1784e+00],\n",
            "        [ 4.0844e+00],\n",
            "        [ 4.2431e+00],\n",
            "        [ 4.1961e+00],\n",
            "        [ 4.1392e+00],\n",
            "        [ 4.1294e+00],\n",
            "        [ 4.3529e+00],\n",
            "        [ 4.3529e+00],\n",
            "        [ 4.3979e+00],\n",
            "        [ 4.3920e+00],\n",
            "        [ 4.2705e+00],\n",
            "        [ 4.1784e+00],\n",
            "        [ 4.3391e+00],\n",
            "        [ 4.3999e+00],\n",
            "        [ 4.2784e+00],\n",
            "        [ 4.0393e+00],\n",
            "        [ 4.0197e+00],\n",
            "        [ 4.0354e+00],\n",
            "        [ 3.6434e+00],\n",
            "        [ 3.4631e+00],\n",
            "        [ 3.5395e+00],\n",
            "        [ 3.3141e+00],\n",
            "        [ 3.3435e+00],\n",
            "        [ 3.2044e+00],\n",
            "        [ 3.1338e+00],\n",
            "        [ 3.1280e+00],\n",
            "        [ 2.9281e+00],\n",
            "        [ 2.8340e+00],\n",
            "        [ 2.8066e+00],\n",
            "        [ 2.9418e+00],\n",
            "        [ 3.1260e+00],\n",
            "        [ 3.2534e+00],\n",
            "        [ 3.1064e+00],\n",
            "        [ 3.0339e+00],\n",
            "        [ 2.9516e+00],\n",
            "        [ 2.7184e+00],\n",
            "        [ 2.8046e+00],\n",
            "        [ 2.7634e+00],\n",
            "        [ 2.7438e+00],\n",
            "        [ 2.5361e+00]]), 'future_values': tensor([[ 2.2794],\n",
            "        [ 2.1206],\n",
            "        [ 1.8521],\n",
            "        [ 1.9540],\n",
            "        [ 1.6032],\n",
            "        [ 1.6542],\n",
            "        [ 1.4562],\n",
            "        [ 1.4112],\n",
            "        [ 1.3426],\n",
            "        [ 1.3171],\n",
            "        [ 1.1799],\n",
            "        [ 1.1760],\n",
            "        [ 0.8977],\n",
            "        [ 0.7017],\n",
            "        [ 0.5057],\n",
            "        [ 0.3431],\n",
            "        [ 0.2196],\n",
            "        [ 0.0706],\n",
            "        [ 0.0648],\n",
            "        [ 0.0942],\n",
            "        [-0.0822],\n",
            "        [-0.1077],\n",
            "        [-0.1332],\n",
            "        [-0.1547],\n",
            "        [-0.4174],\n",
            "        [-0.4585],\n",
            "        [-0.5330],\n",
            "        [-0.8270],\n",
            "        [-0.9524],\n",
            "        [-1.0523],\n",
            "        [-1.0955],\n",
            "        [-1.3287],\n",
            "        [-1.1464],\n",
            "        [-1.1307],\n",
            "        [-1.3110],\n",
            "        [-1.2405],\n",
            "        [-1.3012],\n",
            "        [-1.2150],\n",
            "        [-1.3345],\n",
            "        [-1.3463],\n",
            "        [-1.3404],\n",
            "        [-1.3404],\n",
            "        [-1.3052],\n",
            "        [-1.2522],\n",
            "        [-1.2718],\n",
            "        [-1.3385],\n",
            "        [-1.2189],\n",
            "        [-1.3169],\n",
            "        [-1.2601],\n",
            "        [-1.3247],\n",
            "        [-1.3659],\n",
            "        [-1.3424],\n",
            "        [-1.3208],\n",
            "        [-1.2405],\n",
            "        [-1.2562],\n",
            "        [-1.2366],\n",
            "        [-1.3169],\n",
            "        [-1.2660],\n",
            "        [-1.2542],\n",
            "        [-1.3345],\n",
            "        [-1.2973],\n",
            "        [-1.2836],\n",
            "        [-1.3796],\n",
            "        [-1.3345],\n",
            "        [-1.4345],\n",
            "        [-1.4227],\n",
            "        [-1.3600],\n",
            "        [-1.2934],\n",
            "        [-1.3894],\n",
            "        [-1.4149],\n",
            "        [-1.4208],\n",
            "        [-1.4071],\n",
            "        [-1.4463],\n",
            "        [-1.5364],\n",
            "        [-1.4443],\n",
            "        [-1.4129],\n",
            "        [-1.4698],\n",
            "        [-1.4678],\n",
            "        [-1.5070],\n",
            "        [-1.4580],\n",
            "        [-1.4541],\n",
            "        [-1.3894],\n",
            "        [-1.3698],\n",
            "        [-1.3463],\n",
            "        [-1.2816],\n",
            "        [-1.2150],\n",
            "        [-1.2130],\n",
            "        [-1.0896],\n",
            "        [-1.1719],\n",
            "        [-1.1033],\n",
            "        [-1.0229],\n",
            "        [-1.0229],\n",
            "        [-1.0661],\n",
            "        [-1.0151],\n",
            "        [-0.9602],\n",
            "        [-0.8564]]), 'past_observed_mask': tensor([[True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True]]), 'future_observed_mask': tensor([[True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True]]), 'timestamp': Timestamp('2024-06-26 00:00:00'), 'id': (0, 0)}\n"
          ]
        }
      ],
      "source": [
        "# fewshot_finetune_eval(\n",
        "#     dataset_name=TARGET_DATASET,\n",
        "#     context_length=CONTEXT_LENGTH,\n",
        "#     forecast_length=PREDICTION_LENGTH,\n",
        "#     batch_size=32,\n",
        "#     fewshot_percent=30,\n",
        "#     learning_rate=0.001,\n",
        "#     num_epochs=20\n",
        "# )\n",
        "\n",
        "fewshot_finetune_eval(\n",
        "    dataset_name=TARGET_DATASET,\n",
        "    context_length=CONTEXT_LENGTH,\n",
        "    forecast_length=PREDICTION_LENGTH,\n",
        "    batch_size=32,\n",
        "    fewshot_percent=5,\n",
        "    learning_rate=0.001,\n",
        "    num_epochs=1\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}